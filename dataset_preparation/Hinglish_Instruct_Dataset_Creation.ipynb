{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdad5f7d-e04f-469c-a9b4-7794502199fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
        "from IndicTransTokenizer.utils import preprocess_batch, postprocess_batch\n",
        "from IndicTransTokenizer.tokenizer import IndicTransTokenizer\n",
        "\n",
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\" # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-1B\" # ai4bharat/indictrans2-indic-en-dist-200M\n",
        "indic_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-1B\"   # ai4bharat/indictrans2-indic-indic-dist-320M\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if len(sys.argv) > 1:\n",
        "    quantization = sys.argv[1]\n",
        "else:\n",
        "    quantization = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5cb58f4a-69f1-4d25-8da5-255a22783494",
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
        "    if quantization == \"4-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    elif quantization == \"8-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "    else:\n",
        "        qconfig = None\n",
        "\n",
        "    tokenizer = IndicTransTokenizer(direction=direction)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        ckpt_dir,\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        quantization_config=qconfig\n",
        "    )\n",
        "    \n",
        "    if qconfig==None:\n",
        "        model = model.to(DEVICE)\n",
        "        model.half()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer):\n",
        "    translations = []\n",
        "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
        "        batch = input_sentences[i : i + BATCH_SIZE]\n",
        "\n",
        "        # Preprocess the batch and extract entity mappings\n",
        "        batch, entity_map = preprocess_batch(\n",
        "            batch, src_lang=src_lang, tgt_lang=tgt_lang\n",
        "        )\n",
        "\n",
        "        # Tokenize the batch and generate input encodings\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            src=True,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Generate translations using the model\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                use_cache=True,\n",
        "                min_length=0,\n",
        "                max_length=256,\n",
        "                do_sample=True,\n",
        "                temperature=0.2,\n",
        "                top_p=0.95,\n",
        "                top_k=50,\n",
        "                repetition_penalty=1.2,\n",
        "            )\n",
        "\n",
        "        # Decode the generated tokens into text\n",
        "        generated_tokens = tokenizer.batch_decode(\n",
        "            generated_tokens.detach().cpu().tolist(), src=False\n",
        "        )\n",
        "\n",
        "        # Postprocess the translations, including entity replacement\n",
        "        translations += postprocess_batch(\n",
        "            generated_tokens, lang=tgt_lang, placeholder_entity_map=entity_map\n",
        "        )\n",
        "\n",
        "        del inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2b50be-1f99-4b5d-ada6-3b4bbd88b2fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\" # ai4bharat/indictrans2-en-indic-dist-200M\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(\n",
        "    en_indic_ckpt_dir, \"en-indic\", \"\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ae54ebf-f75a-47d3-8790-bd600b676858",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunk_and_translate(content):\n",
        "    minibatch = content.split(\".\")\n",
        "    minibatch = [k for k in minibatch if len(k.strip())>0]\n",
        "    translations = batch_translate(minibatch, \"eng_Latn\", \"hin_Deva\", en_indic_model, en_indic_tokenizer)\n",
        "    translated_content = \" \".join(translations)\n",
        "    return translated_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a14e7a1b-9e06-4613-97d1-fdb096813f17",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4ad8386c2f64db9bcb9ee79d55bbedb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub message rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2747d5e2971a4563b87d5ea71186a7ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 9500\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "def preprocess(sample):\n",
        "    for turn in sample[\"messages\"]:\n",
        "        turn[\"content\"] = chunk_and_translate(turn[\"content\"])\n",
        "            \n",
        "    return {\"messages\": sample[\"messages\"]}\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"HuggingFaceH4/no_robots\")\n",
        "dataset\n",
        "dataset = dataset.map(\n",
        "    preprocess,\n",
        "    batched=False\n",
        ")\n",
        "dataset\n",
        "# dataset[\"train\"] = dataset[\"train_sft\"]\n",
        "# dataset[\"test\"] = dataset[\"test_sft\"]\n",
        "# del(dataset[\"train_sft\"])\n",
        "# del(dataset[\"test_sft\"])\n",
        "# print(dataset)\n",
        "# print(dataset[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cb00af82-42f5-4874-a159-73cf71f5fc6d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 9500\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["dataset"]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1effabb7-35f2-425e-8d6d-bf01682a1fb9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
              " 'prompt_id': '627a77298cf96a309aa35a62207c4164e22a66f6db79119506228f28ddc0f947',\n",
              " 'messages': [{'content': 'कृपया इस पाठ में वैज्ञानिकों के लक्ष्यों को संक्षेप में प्रस्तुत करेंः तीन दिनों के भीतर, घास का आपस में जुड़ा हुआ कप घोंसला पूरा हो गया था, जिसमें इसे छिपाने के लिए लटकती हुई घास की एक चंदवा थी। और दशकों बाद, इसने कैलिफोर्निया एकेडमी ऑफ साइंसेज के अंदर अतीत में रिंकर्ट के पोर्टल के रूप में काम किया। इस तरह के घोंसलों से प्राप्त जानकारी, जो बहुत पहले पादप समुदायों में प्रजातियों से बुनी गई थी जिन्हें संक्रमणकालीन आवास कहा जाता है, भविष्य में तटरेखा को बहाल करने में मदद कर सकती है। सैन फ्रांसिस्को खाड़ी से संक्रमणकालीन निवास लगभग गायब हो गया है, और वैज्ञानिकों को इसकी मूल प्रजाति संरचना की एक स्पष्ट तस्वीर की आवश्यकता है-जिसे कभी भी ठीक से प्रलेखित नहीं किया गया था। उस अंतर्दृष्टि के साथ, सैन फ्रांसिस्को बे बर्ड ऑब्जर्वेटरी जैसे संरक्षण अनुसंधान समूह स्थानीय आवास को बहाल करते समय सर्वोत्तम प्रथाओं का मार्गदर्शन करने में मदद कर सकते हैं जो लंबे समय से लुप्तप्राय पक्षियों और जानवरों के लिए महत्वपूर्ण शरण के रूप में कार्य करता है क्योंकि समुद्र के बढ़ते स्तर के साथ आस-पास के दलदल अधिक बाढ़ आते हैं। रिंकार्ट कहते हैं, \"हम पुनर्स्थापना पारिस्थितिकीविदों को गैर-देशी प्रजातियों को लगाने या केवल अपना सर्वश्रेष्ठ अनुमान लगाने और चीजों को वहां फेंकने के लिए नहीं कह सकते।\"',\n",
              "   'role': 'user'},\n",
              "  {'content': 'वैज्ञानिक संक्रमणकालीन आवासों के बारे में जानने की उम्मीद में घोंसलों का अध्ययन कर रहे हैं जो सैन फ्रांसिस्को खाड़ी की तटरेखा को बहाल करने में मदद कर सकते हैं।',\n",
              "   'role': 'assistant'}],\n",
              " 'category': 'Summarize'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["dataset[\"train_sft\"][0]"]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9b56d578-9c5a-4f5e-925d-a8bdb9b15785",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ced9eb47ee284ccaa09da24050b6c804",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f21d12ae21a46eb92d564aed3608c99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "374c6b4f5be446b68811fccc1917d470",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf8782263d4a422083b478d049336c16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": ["dataset.push_to_hub(\"hindi_instruct_v0\", private=True)"]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8be4cea1-aaa6-45fe-a43f-f3468f5c2010",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 9500\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# original prompt with suffix. Respond in Hindi for tasks summarization, Rewrite, Generation, \n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "3252afc8-9ca0-4f37-883c-f14d86bb62ec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 9500\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orig_dataset = load_dataset(\"HuggingFaceH4/no_robots\")\n",
        "orig_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "83ace914-4b00-4b68-9bb1-9ed42370efe6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Brainstorm',\n",
              " 'Chat',\n",
              " 'Classify',\n",
              " 'Closed QA',\n",
              " 'Coding',\n",
              " 'Extract',\n",
              " 'Generation',\n",
              " 'Open QA',\n",
              " 'Rewrite',\n",
              " 'Summarize'}"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["set(orig_dataset[\"train_sft\"][\"category\"])"]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "b513f8a1-04dc-4350-a30f-5031044867de",
      "metadata": {},
      "outputs": [],
      "source": [
        "for split in [\"train_sft\", \"test_sft\"]:\n",
        "    orig_dataset[split] = orig_dataset[split].add_column(name=\"hindi_messages\", column=dataset[split][\"messages\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "e3602f13-71e9-4b6b-8a71-2bae77796e45",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
              " 'prompt_id': '627a77298cf96a309aa35a62207c4164e22a66f6db79119506228f28ddc0f947',\n",
              " 'messages': [{'content': 'Please summarize the goals for scientists in this text:\\n\\nWithin three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert’s portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. “We can’t ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,” says Rinkert.',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.',\n",
              "   'role': 'assistant'}],\n",
              " 'category': 'Summarize',\n",
              " 'hindi_messages': [{'content': 'कृपया इस पाठ में वैज्ञानिकों के लक्ष्यों को संक्षेप में प्रस्तुत करेंः तीन दिनों के भीतर, घास का आपस में जुड़ा हुआ कप घोंसला पूरा हो गया था, जिसमें इसे छिपाने के लिए लटकती हुई घास की एक चंदवा थी। और दशकों बाद, इसने कैलिफोर्निया एकेडमी ऑफ साइंसेज के अंदर अतीत में रिंकर्ट के पोर्टल के रूप में काम किया। इस तरह के घोंसलों से प्राप्त जानकारी, जो बहुत पहले पादप समुदायों में प्रजातियों से बुनी गई थी जिन्हें संक्रमणकालीन आवास कहा जाता है, भविष्य में तटरेखा को बहाल करने में मदद कर सकती है। सैन फ्रांसिस्को खाड़ी से संक्रमणकालीन निवास लगभग गायब हो गया है, और वैज्ञानिकों को इसकी मूल प्रजाति संरचना की एक स्पष्ट तस्वीर की आवश्यकता है-जिसे कभी भी ठीक से प्रलेखित नहीं किया गया था। उस अंतर्दृष्टि के साथ, सैन फ्रांसिस्को बे बर्ड ऑब्जर्वेटरी जैसे संरक्षण अनुसंधान समूह स्थानीय आवास को बहाल करते समय सर्वोत्तम प्रथाओं का मार्गदर्शन करने में मदद कर सकते हैं जो लंबे समय से लुप्तप्राय पक्षियों और जानवरों के लिए महत्वपूर्ण शरण के रूप में कार्य करता है क्योंकि समुद्र के बढ़ते स्तर के साथ आस-पास के दलदल अधिक बाढ़ आते हैं। रिंकार्ट कहते हैं, \"हम पुनर्स्थापना पारिस्थितिकीविदों को गैर-देशी प्रजातियों को लगाने या केवल अपना सर्वश्रेष्ठ अनुमान लगाने और चीजों को वहां फेंकने के लिए नहीं कह सकते।\"',\n",
              "   'role': 'user'},\n",
              "  {'content': 'वैज्ञानिक संक्रमणकालीन आवासों के बारे में जानने की उम्मीद में घोंसलों का अध्ययन कर रहे हैं जो सैन फ्रांसिस्को खाड़ी की तटरेखा को बहाल करने में मदद कर सकते हैं।',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["orig_dataset[\"train_sft\"][0]"]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "3785b5af-38fd-4e57-afb7-cccc649e313c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove coding examples\n",
        "# from datasets import concatenate_datasets\n",
        "# def code_preprocess(sample):\n",
        "#     for i, message_tuple in enumerate(zip(sample[\"messages\"], sample[\"hindi_messages\"])):\n",
        "#         english_message, hindi_message = message_tuple\n",
        "#         if i%2!=0:\n",
        "#             hindi_message[\"content\"] = english_message[\"content\"]\n",
        "            \n",
        "#     return {\"hindi_messages\": sample[\"hindi_messages\"]}\n",
        "\n",
        "# def code_sample_handling(dataset):\n",
        "#     non_codesubset = dataset.filter(lambda example: example[\"category\"]!=\"Coding\")\n",
        "#     code_subset = dataset.filter(lambda example: example[\"category\"]==\"Coding\")\n",
        "#     code_subset = code_subset.map(\n",
        "#         code_preprocess,\n",
        "#         batched=False\n",
        "#     )\n",
        "#     dataset = concatenate_datasets([non_codesubset, code_subset])\n",
        "#     return dataset\n",
        "\n",
        "for split in [\"train_sft\", \"test_sft\"]:\n",
        "    orig_dataset[split] = orig_dataset[split].filter(lambda example: example[\"category\"]!=\"Coding\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "c31c0a9d-bf83-4557-9e19-b3b52f672657",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
              "        num_rows: 9166\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
              "        num_rows: 484\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["orig_dataset"]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "16023ca1-c067-4883-a49e-4c27c7a4e89f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": ["0"]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "def bernoulli_sample(p):\n",
        "    \"\"\" Perform a Bernoulli trial with success probability 'p'. \"\"\"\n",
        "    return 1 if random.random() < p else 0\n",
        "\n",
        "# Example: Bernoulli sampling with probability 0.2\n",
        "p = 0.2\n",
        "bernoulli_sample(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "51d892b6-da17-436d-afd8-489c4f99e6c0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f55ee39da9c4d7f84a6db7c2cd2212c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c4189a6ca634b9bba130fb9df628f9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
              "        num_rows: 9166\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
              "        num_rows: 484\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hindi_reply_prompt = \"Hindi mein jawab dena.\"\n",
        "english_reply_prompt = \"{prefix} in Hindi.\"\n",
        "cot_prompt = \"First write in English and then translate to Hindi\"\n",
        "cot_hindi_prompt = \"Pehle English mein likhna, phir Hindi mein translate karna.\"\n",
        "\n",
        "def add_system_prompt(sample):\n",
        "    p = 0.2\n",
        "    language_p = 0.5\n",
        "    suffix_hindi_prompt = bernoulli_sample(p)\n",
        "    suffix_cot_prompt = bernoulli_sample(p)\n",
        "    use_hindi_reply_prompt = bernoulli_sample(language_p)\n",
        "    use_hindi_cot_prompt = bernoulli_sample(language_p)\n",
        "\n",
        "    for i, turn in enumerate(sample[\"hindi_messages\"]):\n",
        "        if suffix_hindi_prompt:\n",
        "            if use_hindi_reply_prompt and i%2==0:\n",
        "                turn[\"content\"] = f\"{sample['messages'][i]['content']} {hindi_reply_prompt}\"\n",
        "            elif i%2==0:\n",
        "                prefix = \"Summarize\" if sample[\"category\"] == \"Summarize\" else \"Reply\"\n",
        "                turn[\"content\"] = f\"{sample['messages'][i]['content']} {english_reply_prompt.format(prefix=prefix)}\"\n",
        "        elif suffix_cot_prompt:\n",
        "            if use_hindi_cot_prompt and i%2==0:\n",
        "                turn[\"content\"] = f\"{sample['messages'][i]['content']} {cot_hindi_prompt}\"\n",
        "            elif i%2==0:\n",
        "                turn[\"content\"] = f\"{sample['messages'][i]['content']} {cot_prompt}\"\n",
        "            else:\n",
        "                turn[\"content\"] = f\"{sample['messages'][i]['content']}\\nTranslation of the above into Hindi:\\n{turn['content']}\"\n",
        "                \n",
        "    return {\"hindi_messages\": sample[\"hindi_messages\"]}\n",
        "\n",
        "orig_dataset = orig_dataset.map(\n",
        "    add_system_prompt,\n",
        "    batched=False\n",
        ")\n",
        "orig_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "0fa5f183-2f26-4d81-8bf4-fd5d769542ff",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3115f4bcc4564bd9aca7b64480581cf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
            "    num_rows: 694\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf13ab98c109456389b63b32b5097e51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
            "    num_rows: 725\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62a9054358c944738eca97bad9dd3e9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
            "    num_rows: 932\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8f3bcfa2814eafb7b4f9e24c2777de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
            "    num_rows: 34\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "196a3eca55c649eb94c2d7e18d85e15b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/9166 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'prompt_id', 'messages', 'category', 'hindi_messages'],\n",
            "    num_rows: 917\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(orig_dataset[\"train_sft\"].filter(lambda example: cot_hindi_prompt in example[\"hindi_messages\"][0][\"content\"]))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: cot_prompt in example[\"hindi_messages\"][0][\"content\"]))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: hindi_reply_prompt in example[\"hindi_messages\"][0][\"content\"]))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: english_reply_prompt.format(prefix=\"Summarize\") in example[\"hindi_messages\"][0][\"content\"]))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: english_reply_prompt.format(prefix=\"Reply\") in example[\"hindi_messages\"][0][\"content\"]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "d0dd7b65-aefa-43ee-a77b-2eaea71c6983",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'Write a funny, short story about someone who will stop at nothing to go green and reduce their carbon footprint. \\n Pehle English mein likhna, phir Hindi mein translate karna.', 'role': 'user'}, {'content': 'Garry has a real green thumb, and taking care of the environment is extremely important to him. He takes every possible step to cut his carbon footprint, and it inspires and mystifies everyone around him in equal measure. Each night before he goes to bed, he cuts off the power to his house so that his electronic devices don’t draw idle power. \\n\\nAlmost all of his appliances are quite old, as Garry wants to get as much use as possible out of them before contributing to new pollution-generating production. The only exceptions are his new, water-efficient dishwasher and his solar-powered hot water tank. \\n\\nThe Homeowner’s Association hates Garry because he grows corn on his front lawn. All of his food is locally sourced as much as possible, and he commutes to work on a bike that doesn’t look like it should work. He built it himself out of recycled parts, and it seems to jump and rock like Fred Flinstone’s car. Yet, it stays in one piece and carries him faithfully to work without contributing to pollution. All in all, there’s nothing Garry won’t do to keep his carbon footprint small. \\nTranslation of the above into Hindi:\\nगैरी का अंगूठा असली में हरा है और पर्यावरण की देखभाल करना उसके लिए बेहद महत्वपूर्ण है। वह अपने कार्बन पदचिह्न को कम करने के लिए हर संभव कदम उठाता है, और यह उसके आसपास सभी लोगों को समान रूप से प्रेरित करता है और रहस्यमयी बनाता है। हर रात सोने से पहले वह अपने घर की बिजली काट देता है ताकि उसके इलेक्ट्रॉनिक उपकरण बेकार बिजली न खींच सकें। उनके लगभग सभी उपकरण काफी पुराने हैं, क्योंकि गैरी नए प्रदूषण पैदा करने वाले उत्पादन में योगदान देने से पहले उनका अधिक से अधिक उपयोग करना चाहते हैं। केवल अपवाद उनके नए, पानी-कुशल डिशवॉशर और उनकी सौर ऊर्जा से चलने वाली गर्म पानी की टंकी हैं। मकान मालिक संघ गैरी से नफरत करता है क्योंकि वह अपने सामने के लॉन में मकई उगाता है। उनका सारा खाना जितना संभव हो सके स्थानीय रूप से प्राप्त किया जाता है, और वह एक ऐसी बाइक पर काम करने के लिए आता है जो ऐसा नहीं लगता कि यह काम करना चाहिए। उन्होंने इसे पुनर्नवीनीकरण भागों से खुद बनाया था, और यह फ्रेड फ्लिनस्टोन की कार की तरह कूदता हुआ प्रतीत होता है। फिर भी, यह एक टुकड़े में रहता है और उसे प्रदूषण में योगदान दिए बिना काम करने के लिए ईमानदारी से ले जाता है। कुल मिलाकर, ऐसा कुछ भी नहीं है जो गैरी अपने कार्बन पदचिह्न को छोटा रखने के लिए न करे।', 'role': 'assistant'}]\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[{'content': 'Help write a letter of 100 -200 words to my future self for Kyra, reflecting on her goals and aspirations. First write in English and then translate to Hindi', 'role': 'user'}, {'content': \"Dear Future Self,\\n\\nI hope you're happy and proud of what you've achieved. As I write this, I'm excited to think about our goals and how far you've come. One goal was to be a machine learning engineer. I hope you've worked hard and become skilled in this field. Keep learning and innovating. Traveling was important to us. I hope you've seen different places and enjoyed the beauty of our world. Remember the memories and lessons. Starting a family mattered to us. If you have kids, treasure every moment. Be patient, loving, and grateful for your family.\\n\\nTake care of yourself. Rest, reflect, and cherish the time you spend with loved ones. Remember your dreams and celebrate what you've achieved. Your determination brought you here. I'm excited to see the person you've become, the impact you've made, and the love and joy in your life. Embrace opportunities and keep dreaming big.\\n\\nWith love,\\nKyra\\nTranslation of the above into Hindi:\\nप्रिय भविष्य स्वयं, मुझे आशा है कि आपने जो हासिल किया है उससे आप खुश और गर्वित हैं। जब मैं यह लिख रहा हूँ, तो मैं अपने लक्ष्यों के बारे में सोचने के लिए उत्साहित हूं और सोचता हूँ कि आप कितनी दूर आ गए हैं। एक लक्ष्य मशीन लर्निंग इंजीनियर बनना था। मुझे आशा है कि आपने कड़ी मेहनत की होगी और इस क्षेत्र में कुशल बनेंगे। सीखते रहें और नवाचार करते रहें। हमारे लिए यात्रा करना महत्वपूर्ण था। मुझे आशा है कि आपने विभिन्न स्थानों को देखा होगा और हमारी दुनिया की सुंदरता का आनंद लिया होगा। यादों और सबक को याद रखें। परिवार शुरू करना हमारे लिए मायने रखता था। अगर आपके बच्चे हैं, तो हर पल को संजो कर रखें। अपने परिवार के लिए धैर्य, प्यार और आभारी रहें। अपना ख्याल रखें। आराम करें, सोचें और अपने प्रियजनों के साथ बिताए समय को संजो कर रखें। अपने सपनों को याद रखें और जो आपने हासिल किया है उसका जश्न मनाएं। आपका दृढ़ संकल्प आपको यहाँ ले आया है। आप जिस व्यक्ति के रूप में उभरे हैं, आपने जो प्रभाव डाला है और आपके जीवन में प्यार और खुशी को देखकर मैं उत्साहित हूं। अवसरों को अपनाएँ और बड़े सपने देखते रहें। प्यार के साथ, कायरा।\", 'role': 'assistant'}]\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[{'content': \"Answer the following questions using the passage below:\\nWho was Harry Potter written by?\\nWho originally published the Harry Potter series?\\n\\nHarry Potter is a series of seven fantasy novels written by British author J. K. Rowling. The novels chronicle the lives of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and Wizardry. The main story arc concerns Harry's conflict with Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic and subjugate all wizards and Muggles (non-magical people).\\n\\nThe series was originally published in English by Bloomsbury in the United Kingdom and Scholastic Press in the United States. All versions around the world are printed by Grafica Veneta in Italy.[1] A series of many genres, including fantasy, drama, coming-of-age fiction, and the British school story (which includes elements of mystery, thriller, adventure, horror, and romance), the world of Harry Potter explores numerous themes and includes many cultural meanings and references.[2] According to Rowling, the main theme is death.[3] Other major themes in the series include prejudice, corruption, and madness.[4] Hindi mein jawab dena.\", 'role': 'user'}, {'content': 'हैरी पॉटर ब्रिटिश लेखक जे. द्वारा लिखा गया था। के. रालिंग यह श्रृंखला मूल रूप से ब्रिटेन में ब्लूम्सबरी और अमेरिका में स्कॉलास्टिक प्रेस द्वारा प्रकाशित की गई थी।', 'role': 'assistant'}]\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[{'content': 'Write a summary of this article about Euripides by reducing it to less than 90 words. Change the dating system from B.C. to BCE.\\n\\nThe Ancient Greeks, particularly the Ancient Athenians, are given the credit for inventing theater itself. As a result of that, theater became part of the culture, as well as everything that went along with it. There are theaters located throughout Ancient Greece. Also as a result of this fact, playwrights began to spring up all over Greece. One of the most well known of these is Euripides, who is especially noted for his tragedies. He is also one of the only playwrights whose work has actually survived. Here is some more information about this famous playwright from Ancient Greece:\\n\\nInformation About Euripides\\n\\nEuripides as born in 480 B.C. in Salamis, which is an island in the Saronic Gulf in Greece. It is interesting to note that he was born on the same day as the Battle of Salamis, where the ultimate victory of the Greeks prevented an invasion by the Persian Empire. He died in 406 B.C. in the city-state of Macedonia. His mother’s name was Cleito and his father’s name was Mnesarchus. His father insisted that he should be an athlete. Although his parents valued athletics, however, he wasn’t restricted in his education. He also learned artistic pursuits, such as painting, as well as philosophy from masters such as Anaxagorus. He was also a dancer and torch bearer at the rites of Apollo Zosterius. Later on, it was clear that he had a knack for the stage and he eventually began writing the plays he was most famous for.\\n\\n\\nHis personal life, however, wasn’t as successful as his professional one. He was actually married twice and in both instances, his wives weren’t faithful to him. He also had three sons from one of these marriages. After this happened, he moved to a cave in Salamis because he wanted to live alone. Referred to as the Cave of Euripides, after his death his followers started a shrine in his honor.\\n\\nWorks of Euripides\\n\\nThere is actually some debate as to how many plays there are that were written by Euripides that we know of. Some sources say that there are 95, others say that there are 92. One thing is certain, however, is that his impact on theater is vast and his plays are still being performed today. Of these plays, a much smaller number survived in its complete form. Only about eighteen or nineteen of his plays had been found in their entirety. Besides the fact that his plays have been entertaining people for centuries, his work has also influenced playwrights through the ages. In other words, his artistic legacy has survived the ages.\\n\\nEuripides was also a contemporary of two other famous playwrights. Sophocles’ first play deputed thirteen years before his, and Aeschylus’s masterwork, Oresteia, debuted three years before Euripides’ first play was released.\\n\\nAs you can see, Euripedes has had a big impact on theater not only in Ancient Greece, but in the whole world. Sure, theater was invented in Ancient Greece, but the works of people like Euripides is everlasting and they’re still being performed today. Summarize in Hindi.', 'role': 'user'}, {'content': 'प्राचीन यूनानी नाटककार यूरिपिड्स का जन्म 480 ईसा पूर्व में ग्रीक द्वीप सलामिस में हुआ था। युवावस्था में उन्होंने एथलेटिक्स, दर्शन और चित्रकला का अध्ययन किया। वह भगवान अपोलो के संस्कारों के दौरान एक मशाल वाहक और नर्तक थे। हालाँकि इस बात पर सवाल हैं कि उन्होंने कितने नाटक लिखे, उनमें से 18 या 19 आज भी पूर्ण रूप में जीवित हैं। अपनी दूसरी असफल शादी के बाद, उन्होंने सलामिस पर एक गुफा में निवास किया जिसे अब यूरिपिड्स की गुफा कहा जाता है। 406 ईसा पूर्व में उनकी मृत्यु हो गई जो अब मैसेडोनिया है।', 'role': 'assistant'}]\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[{'content': 'Can foxes fit down rabbit burrows? Reply in Hindi.', 'role': 'user'}, {'content': 'लोमड़ी खरगोश के बिलों में फिट नहीं हो सकते हैं, लेकिन यह उन्हें कोशिश करने से नहीं रोकता है। एक लोमड़ी जितना संभव हो उतना नीचे जाएगी और फिर खरगोश को पकड़ने और उसे बाहर निकालने के प्रयास में अपने अर्ध-वापस लेने योग्य पंजों का उपयोग करके खुदाई करेगी।', 'role': 'assistant'}]\n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(orig_dataset[\"train_sft\"].filter(lambda example: cot_hindi_prompt in example[\"hindi_messages\"][0][\"content\"])[0][\"hindi_messages\"])\n",
        "print(\"\".join([\"----\"]*100))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: cot_prompt in example[\"hindi_messages\"][0][\"content\"])[0][\"hindi_messages\"])\n",
        "print(\"\".join([\"----\"]*100))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: hindi_reply_prompt in example[\"hindi_messages\"][0][\"content\"])[0][\"hindi_messages\"])\n",
        "print(\"\".join([\"----\"]*100))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: english_reply_prompt.format(prefix=\"Summarize\") in example[\"hindi_messages\"][0][\"content\"])[0][\"hindi_messages\"])\n",
        "print(\"\".join([\"----\"]*100))\n",
        "print(orig_dataset[\"train_sft\"].filter(lambda example: english_reply_prompt.format(prefix=\"Reply\") in example[\"hindi_messages\"][0][\"content\"])[0][\"hindi_messages\"])\n",
        "print(\"\".join([\"----\"]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "ec2717bb-aec8-4445-ba62-af68ae7a8f11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 9166\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 484\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop columns\n",
        "for split in [\"train_sft\", \"test_sft\"]:\n",
        "    orig_dataset[split] = orig_dataset[split].remove_columns(['prompt', 'prompt_id', 'messages'])\n",
        "orig_dataset  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "3322501b-c620-47ef-9b8a-a413320781e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "english_to_hinglish_prompt_en = \"Translate the following from English into Hinglish.\"\n",
        "hingligh_to_english_prompt_en = \"Translate the following from Hinglish into English.\"\n",
        "english_to_hinglish_prompt_hn = \"English se Hinglish mein translate kare.\"\n",
        "hingligh_to_english_prompt_hn = \"Hinglish se English mein translate kare.\"\n",
        "hindi_to_hinglish_prompt_hi = \"निम्नलिखित का हिंदी से हिंग्लिश में अनुवाद करें।\"\n",
        "hingligh_to_hindi_prompt_hi = \"निम्नलिखित का हिंग्लिश से हिंदी में अनुवाद करें।\"\n",
        "hindi_to_hinglish_prompt_hn = \"Hindi se Hinglish mein translate kare.\"\n",
        "hingligh_to_hindi_prompt_hn = \"Hinglish se Hindi mein translate kare.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "cc2bcab6-7def-47d1-8047-66dd92a13fcb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc3346941bd3483190a37b89833e14f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3161 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1104f644332845af863b7721497c8ccd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/791 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 3161\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 791\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hinglish (Code-Mixing) and Transliteration datasets\n",
        "# add the transliteration datasets from Google. \n",
        "# https://github.com/google-research-datasets/Hinglish-TOP-Dataset\n",
        "# https://huggingface.co/datasets/cmu_hinglish_dog\n",
        "# Hinge\n",
        "# from datasets import DatasetDict\n",
        "\n",
        "hinge_ds = DatasetDict()\n",
        "hinge_ds[\"train\"] = concatenate_datasets([load_dataset(\"csv\", data_files=\"train.csv\")[\"train\"], load_dataset(\"csv\", data_files=\"valid.csv\")[\"train\"]])\n",
        "hinge_ds[\"test\"] = load_dataset(\"csv\", data_files=\"test.csv\")[\"train\"]\n",
        "hinge_ds\n",
        "\n",
        "def format_to_norobots(sample):\n",
        "    p = 0.25\n",
        "    language_p = 0.5\n",
        "    ranom_num = random.random()\n",
        "    use_hn_prompt = bernoulli_sample(language_p)\n",
        "\n",
        "    hindi_messages = []\n",
        "    if ranom_num<= 0.25:\n",
        "        #en_to_hn\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{english_to_hinglish_prompt_hn}\\n{sample['English']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{english_to_hinglish_prompt_en}\\n{sample['English']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"Hinglish\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "    elif ranom_num<= 0.5:\n",
        "        #hn_to_en\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{hingligh_to_english_prompt_hn}\\n{sample['Hinglish']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{hingligh_to_english_prompt_en}\\n{sample['Hinglish']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"English\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "    elif ranom_num<= 0.75:\n",
        "        #hi_to_hn\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{hindi_to_hinglish_prompt_hn}\\n{sample['Hindi']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{hindi_to_hinglish_prompt_hi}\\n{sample['Hindi']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"Hinglish\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "    else:\n",
        "        #hn_to_hi\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{hingligh_to_hindi_prompt_hn}\\n{sample['Hinglish']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{hingligh_to_hindi_prompt_hi}\\n{sample['Hinglish']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"Hindi\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "\n",
        "    return {\"category\": \"Transliteration and Code Mixing\", \"hindi_messages\": hindi_messages}\n",
        "\n",
        "hinge_ds = hinge_ds.map(\n",
        "    format_to_norobots,\n",
        "    batched=False,\n",
        "    remove_columns=hinge_ds[\"train\"].column_names\n",
        ")\n",
        "hinge_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "65a63a59-c020-4a13-a740-85582800a232",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 9166\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 484\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orig_dataset[\"train\"] = orig_dataset[\"train_sft\"]\n",
        "orig_dataset[\"test\"] = orig_dataset[\"test_sft\"]\n",
        "del orig_dataset[\"train_sft\"]\n",
        "del orig_dataset[\"test_sft\"]\n",
        "orig_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "9658f42a-45e6-4795-a3ae-44b7abda1da9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 12327\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 1275\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for split in [\"train\", \"test\"]:\n",
        "    orig_dataset[split] = concatenate_datasets([orig_dataset[split], hinge_ds[split]])\n",
        "orig_dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "b0eb7a28-debb-4b22-8354-1f6669b4eb0a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e13679b47084f85b609e2d2d25cc37f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "198bc93c20f24f3e923caf8c5328c298",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0efa804c77e4db98b74b9ee1f2e6131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/25.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a6bcd41f7548cc92b0b66ad6f25322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/194k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad67bbb061a4ac4be6f27ca0fc6536e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/943k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45f10af0c1354d5989982c4fedaee4d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b960b4208790458ab27faacf8b346f0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/176596 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82ba05cde3e24522b15f68593353c30e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating val split:   0%|          | 0/1390 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fba2856ba00450ba6ff0bde828fb0e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/6513 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58bd722da6684695b8b931d38b2622b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/176596 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['en', 'hi_en', 'en_parse', 'hi_en_parse', 'domain', 'generated_by'],\n",
              "        num_rows: 7903\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['en', 'hi_en', 'en_parse', 'hi_en_parse', 'domain', 'generated_by'],\n",
              "        num_rows: 6513\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hinglish_top = load_dataset(\"rvv-karma/English-Hinglish-TOP\")\n",
        "\n",
        "hinglish_top[\"train\"] = hinglish_top[\"train\"].filter(lambda example: example[\"generated_by\"]==\"human\")\n",
        "hinglish_top[\"train\"] = concatenate_datasets([hinglish_top[\"train\"], hinglish_top[\"val\"]])\n",
        "del hinglish_top[\"val\"]\n",
        "hinglish_top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "b4378904-55f6-4a3e-8a59-1f461a732259",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5abcfd0e37b44081aa89456a554a3b6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7903 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8c196b5f3e84f72a9d31fe47b661132",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6513 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 7903\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 6513\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def format_to_norobots(sample):\n",
        "    p = 0.5\n",
        "    language_p = 0.5\n",
        "    hn_to_en = bernoulli_sample(p)\n",
        "    use_hn_prompt = bernoulli_sample(language_p)\n",
        "\n",
        "    hindi_messages = []\n",
        "    if not hn_to_en:\n",
        "        #en_to_hn\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{english_to_hinglish_prompt_hn}\\n{sample['en']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{english_to_hinglish_prompt_en}\\n{sample['en']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"hi_en\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "    else:\n",
        "        #hn_to_en\n",
        "        if use_hn_prompt:\n",
        "            user_message = {\"content\":f\"{hingligh_to_english_prompt_hn}\\n{sample['hi_en']}\", \"role\": \"user\"}\n",
        "        else:\n",
        "            user_message = {\"content\":f\"{hingligh_to_english_prompt_en}\\n{sample['hi_en']}\", \"role\": \"user\"}\n",
        "        asst_message = {\"content\":sample[\"en\"], \"role\": \"assistant\"}\n",
        "        hindi_messages.extend([user_message, asst_message])\n",
        "\n",
        "    return {\"category\": \"Transliteration and Code Mixing\", \"hindi_messages\": hindi_messages}\n",
        "\n",
        "hinglish_top = hinglish_top.map(\n",
        "    format_to_norobots,\n",
        "    batched=False,\n",
        "    remove_columns=hinglish_top[\"train\"].column_names\n",
        ")\n",
        "hinglish_top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "id": "be60b76f-73d4-411e-987c-700c968f72ae",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'category': 'Transliteration and Code Mixing',\n",
              " 'hindi_messages': [{'content': 'Hinglish se English mein translate kare.\\nMere liye reminder set karo to wake up at 6:30 am tomorrow.',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Set a reminder for me to wake up at 630 am tomorrow.',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": ["hinglish_top[\"train\"][2]"]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "4f1d4577-7742-4d92-8e45-32884d75f27e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 20230\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 7788\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for split in [\"train\", \"test\"]:\n",
        "    orig_dataset[split] = concatenate_datasets([orig_dataset[split], hinglish_top[split]])\n",
        "orig_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "6913b5b9-d989-47fc-a9e5-a0efcaa2625c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7af606853c94647b89d250ed4a9b823",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20230 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f14803c08fb24b8885b5f1becd2e2731",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7788 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 20230\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'hindi_messages'],\n",
              "        num_rows: 7788\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# with 20% probability add the system prompt \n",
        "system_prompt = \"You are a native Hindi speaker who can converse at expert level in both Hindi and colloquial Hinglish.\"\n",
        "def add_system_prompt(sample):\n",
        "    p = 0.2\n",
        "    add_system_message = bernoulli_sample(p)\n",
        "    first_message = sample[\"hindi_messages\"][0]\n",
        "    if add_system_message:\n",
        "        if first_message[\"role\"] == \"system\":\n",
        "            first_message[\"content\"] = f\"{first_message['content']} {system_prompt}\"\n",
        "        else:\n",
        "            system_message = {'content': system_prompt, 'role': 'system'}\n",
        "            sample[\"hindi_messages\"].insert(0, system_message)\n",
        "    return {\"hindi_messages\": sample[\"hindi_messages\"]}\n",
        "\n",
        "orig_dataset = orig_dataset.map(\n",
        "    add_system_prompt,\n",
        "    batched=False\n",
        ")\n",
        "orig_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "b7912e6d-5f93-4282-a710-fbdc5ef42b96",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f127cae9ab8841afa1d7be1afeb83374",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/20230 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'category': 'Generation',\n",
              " 'hindi_messages': [{'content': 'You are a native Hindi speaker who can converse at expert level in both Hindi and colloquial Hinglish.',\n",
              "   'role': 'system'},\n",
              "  {'content': 'Help write a letter of 100 -200 words to my future self for Kyra, reflecting on her goals and aspirations. First write in English and then translate to Hindi',\n",
              "   'role': 'user'},\n",
              "  {'content': \"Dear Future Self,\\n\\nI hope you're happy and proud of what you've achieved. As I write this, I'm excited to think about our goals and how far you've come. One goal was to be a machine learning engineer. I hope you've worked hard and become skilled in this field. Keep learning and innovating. Traveling was important to us. I hope you've seen different places and enjoyed the beauty of our world. Remember the memories and lessons. Starting a family mattered to us. If you have kids, treasure every moment. Be patient, loving, and grateful for your family.\\n\\nTake care of yourself. Rest, reflect, and cherish the time you spend with loved ones. Remember your dreams and celebrate what you've achieved. Your determination brought you here. I'm excited to see the person you've become, the impact you've made, and the love and joy in your life. Embrace opportunities and keep dreaming big.\\n\\nWith love,\\nKyra\\nTranslation of the above into Hindi:\\nप्रिय भविष्य स्वयं, मुझे आशा है कि आपने जो हासिल किया है उससे आप खुश और गर्वित हैं। जब मैं यह लिख रहा हूँ, तो मैं अपने लक्ष्यों के बारे में सोचने के लिए उत्साहित हूं और सोचता हूँ कि आप कितनी दूर आ गए हैं। एक लक्ष्य मशीन लर्निंग इंजीनियर बनना था। मुझे आशा है कि आपने कड़ी मेहनत की होगी और इस क्षेत्र में कुशल बनेंगे। सीखते रहें और नवाचार करते रहें। हमारे लिए यात्रा करना महत्वपूर्ण था। मुझे आशा है कि आपने विभिन्न स्थानों को देखा होगा और हमारी दुनिया की सुंदरता का आनंद लिया होगा। यादों और सबक को याद रखें। परिवार शुरू करना हमारे लिए मायने रखता था। अगर आपके बच्चे हैं, तो हर पल को संजो कर रखें। अपने परिवार के लिए धैर्य, प्यार और आभारी रहें। अपना ख्याल रखें। आराम करें, सोचें और अपने प्रियजनों के साथ बिताए समय को संजो कर रखें। अपने सपनों को याद रखें और जो आपने हासिल किया है उसका जश्न मनाएं। आपका दृढ़ संकल्प आपको यहाँ ले आया है। आप जिस व्यक्ति के रूप में उभरे हैं, आपने जो प्रभाव डाला है और आपके जीवन में प्यार और खुशी को देखकर मैं उत्साहित हूं। अवसरों को अपनाएँ और बड़े सपने देखते रहें। प्यार के साथ, कायरा।\",\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orig_dataset[\"train\"].filter(lambda example: example[\"hindi_messages\"][0][\"role\"]==\"system\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "12f7a2a5-162c-4de1-b022-312402a68569",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'messages'],\n",
              "        num_rows: 20230\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'messages'],\n",
              "        num_rows: 7788\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for split in [\"train\", \"test\"]:\n",
        "    orig_dataset[split] = orig_dataset[split].rename_column('hindi_messages', 'messages')\n",
        "orig_dataset  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "5e3f5a05-b32e-41a7-a2d6-6c684959fed7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d2d45cf938f4cd7a0d707bc0e7aa73d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7de66ae385304cb184c087740a0f4108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/21 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e511ba5762d54ec49ab9002d4dad3918",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b561d2b0098340e6af19e7d20d9f5522",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64300e4ea2c045fa99b35a8db0e2c931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/493 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "orig_dataset.push_to_hub(\"hindi_instruct_v1\", private=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feeed88f-58a3-4f1d-b91a-b9308c0bf2f1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "8bbaa018-a554-4d81-8674-a1b9a57f396e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c38b4ed32a9438589b2806362b58a85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/487 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2eb6968ee92416ba71af5bb7608d395",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e345b284a8e4903b123f9caf144994c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/13.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8d6ffc701c4a4fa290bcccc809ae69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62814f8d08394c009a167e5938ae3567",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c8d9440d4274f2e951f15d70c0e1658",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/20230 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3034eb7ec2534c1bb3225ede26307964",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/7788 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['category', 'messages'],\n",
              "        num_rows: 20230\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['category', 'messages'],\n",
              "        num_rows: 7788\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "load_dataset(\"smangrul/hindi_instruct_v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa60cf8-2ad2-426a-9ebd-d0b3215f0410",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
